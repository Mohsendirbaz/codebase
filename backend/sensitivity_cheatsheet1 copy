## Implementation Plan (continued)

2. **Integrate with Calculations.py**:
   - Add the sensitivity processing function to Calculations.py
   - Update the request handling to process sensitivity parameters

3. **Create HTML and Plot Organization Scripts**:
   - Implement the sensitivity HTML organizer
   - Create a corresponding script for plot organization

4. **Update Routes Blueprint**:
   - Enhance sensitivity routes to use the manager
   - Add endpoints for visualization retrieval

Here's the rest of the implementation:

## 5. Sensitivity Plot Organizer

```python
# sensitivity_plot_organizer.py
import os
import shutil
import logging
from pathlib import Path
import re
import json
from datetime import datetime

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

def organize_sensitivity_plots(base_dir=None):
    """
    Organizes plot files related to sensitivity analysis into standardized 
    album directories for easier frontend consumption.
    """
    # Determine base directory
    if not base_dir:
        # Use same path logic as in the main scripts
        backend_dir = Path(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        base_dir = backend_dir.parent / 'public' / 'Original'
    
    if not os.path.exists(base_dir):
        logger.error(f"Base directory does not exist: {base_dir}")
        return False
    
    # Get all version directories
    logger.info(f"Scanning for version directories in {base_dir}")
    batches = [d for d in os.listdir(base_dir) if d.startswith("Batch(") and d.endswith(")")]
    
    if not batches:
        logger.warning("No batch directories found")
        return False
    
    # Track statistics
    stats = {
        "versions_processed": 0,
        "plots_organized": 0,
        "albums_created": 0
    }
    
    for batch in batches:
        # Extract version number
        version_match = re.match(r"Batch\((\d+)\)", batch)
        if not version_match:
            logger.warning(f"Invalid batch directory format: {batch}")
            continue
            
        version = version_match.group(1)
        results_dir = os.path.join(base_dir, batch, f"Results({version})")
        
        if not os.path.exists(results_dir):
            logger.warning(f"Results directory not found: {results_dir}")
            continue
        
        # Look for Sensitivity directory
        sensitivity_dir = os.path.join(results_dir, "Sensitivity")
        if not os.path.exists(sensitivity_dir):
            logger.info(f"No Sensitivity directory found for version {version}")
            continue
        
        # Create plot albums directory
        plot_albums_dir = os.path.join(results_dir, "SensitivityPlots")
        os.makedirs(plot_albums_dir, exist_ok=True)
        
        # Process different analysis modes
        for mode in ["Symmetrical", "Multipoint"]:
            mode_dir = os.path.join(sensitivity_dir, mode)
            if not os.path.exists(mode_dir):
                continue
            
            # Process different plot types
            for plot_type in ["waterfall", "bar", "point"]:
                plot_type_dir = os.path.join(mode_dir, plot_type)
                
                # If the specific subdirectory doesn't exist, look for plots directly in the mode directory
                if not os.path.exists(plot_type_dir):
                    plot_type_dir = mode_dir
                
                # Find all PNG files of this plot type
                png_files = []
                for root, _, files in os.walk(plot_type_dir):
                    for file in files:
                        if file.lower().endswith('.png') and plot_type in file.lower():
                            png_files.append((os.path.join(root, file), file))
                
                if not png_files:
                    continue
                
                # Create album for this plot type
                album_name = f"Sensitivity_{mode}_{plot_type}"
                album_dir = os.path.join(plot_albums_dir, album_name)
                os.makedirs(album_dir, exist_ok=True)
                stats["albums_created"] += 1
                
                # Process each plot file
                for file_path, file_name in png_files:
                    # Extract parameter info from filename
                    param_match = re.match(r"(.+)_([^_]+)_([^_]+)_(.+)\.png", file_name)
                    if param_match:
                        # Extracted components (may vary depending on naming convention)
                        # In this case: plot_type_paramID_compareToKey_comparisonType.png
                        extracted_plot_type = param_match.group(1)
                        param_id = param_match.group(2)
                        compare_to = param_match.group(3)
                        comparison_type = param_match.group(4)
                        
                        # Create a standardized name
                        new_name = f"{param_id}_vs_{compare_to}_{comparison_type}.png"
                    else:
                        # If pattern doesn't match, keep original name
                        new_name = file_name
                    
                    # Copy the file to the album directory
                    dest_path = os.path.join(album_dir, new_name)
                    if not os.path.exists(dest_path) or os.path.getmtime(file_path) > os.path.getmtime(dest_path):
                        shutil.copy2(file_path, dest_path)
                        logger.info(f"Copied {file_name} to album {album_name} as {new_name}")
                        stats["plots_organized"] += 1
                
                # Create metadata file for the album
                metadata = {
                    "version": version,
                    "mode": mode,
                    "plot_type": plot_type,
                    "files": [os.path.basename(f[0]) for f in png_files],
                    "display_name": f"Sensitivity Analysis - {mode} - {plot_type.capitalize()} Plots",
                    "organized_at": datetime.now().isoformat()
                }
                
                with open(os.path.join(album_dir, "metadata.json"), 'w') as f:
                    json.dump(metadata, f, indent=2)
        
        stats["versions_processed"] += 1
    
    # Log summary statistics
    logger.info(f"Sensitivity plot organization complete: {stats['versions_processed']} versions, "
                f"{stats['albums_created']} albums, {stats['plots_organized']} plots organized")
    return stats

if __name__ == "__main__":
    organize_sensitivity_plots()
```

## 6. Full Stack Integration Module

```python
# sensitivity_integration.py
import logging
import os
import json
import subprocess
from pathlib import Path
from datetime import datetime

# Import our custom modules
from sensitivity_analysis_manager import SensitivityAnalysisManager
from sensitivity_plot_organizer import organize_sensitivity_plots
from sensitivity_html_organizer import organize_sensitivity_html

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

class SensitivityIntegration:
    """
    Integrates sensitivity analysis with the main calculation pipeline.
    This class serves as the central coordinator for all sensitivity-related operations.
    """
    
    def __init__(self):
        self.manager = SensitivityAnalysisManager()
        self.base_dir = Path(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        self.original_dir = self.base_dir.parent / 'public' / 'Original'
        self.logger = logging.getLogger(__name__)
    
    def process_sensitivity_request(self, version, sensitivity_params):
        """
        Process a complete sensitivity analysis request.
        This handles the end-to-end flow from parameter processing to visualization.
        
        Args:
            version: The version number to process
            sensitivity_params: Dictionary of sensitivity parameters with their configurations
        
        Returns:
            dict: Results of the processing operation
        """
        self.logger.info(f"Processing sensitivity request for version {version}")
        
        results = {
            "version": version,
            "timestamp": datetime.now().isoformat(),
            "parameters_processed": [],
            "errors": []
        }
        
        # Filter enabled parameters
        enabled_params = {k: v for k, v in sensitivity_params.items() if v.get('enabled', True)}
        
        if not enabled_params:
            self.logger.info("No enabled sensitivity parameters found")
            return results
        
        # Process each enabled parameter
        for param_id, config in enabled_params.items():
            try:
                self.logger.info(f"Processing parameter {param_id}")
                
                # Validate parameter format
                if not param_id.startswith('S') or not param_id[1:].isdigit():
                    error = f"Invalid parameter ID format: {param_id}"
                    self.logger.error(error)
                    results["errors"].append({"param_id": param_id, "error": error})
                    continue
                
                # Extract and validate configuration
                mode = config.get('mode')
                if not mode:
                    error = f"No analysis mode specified for {param_id}"
                    self.logger.error(error)
                    results["errors"].append({"param_id": param_id, "error": error})
                    continue
                
                compare_to_key = config.get('compareToKey')
                if not compare_to_key:
                    error = f"No comparison key specified for {param_id}"
                    self.logger.error(error)
                    results["errors"].append({"param_id": param_id, "error": error})
                    continue
                
                values = config.get('values', [])
                if mode == 'symmetrical' and (not values or len(values) == 0):
                    # Default value for symmetrical mode
                    values = [10]  # Default to 10% variation
                elif mode == 'multipoint' and (not values or len(values) == 0):
                    error = f"No variation points specified for multipoint analysis of {param_id}"
                    self.logger.error(error)
                    results["errors"].append({"param_id": param_id, "error": error})
                    continue
                
                # Generate sensitivity configurations
                try:
                    configs = self.manager.generate_sensitivity_configs(
                        version, param_id, mode, values
                    )
                    self.logger.info(f"Generated {len(configs)} sensitivity configurations for {param_id}")
                except Exception as e:
                    error = f"Error generating sensitivity configurations for {param_id}: {str(e)}"
                    self.logger.error(error)
                    results["errors"].append({"param_id": param_id, "error": error})
                    continue
                
                # Run calculations for each configuration
                calculation_results = []
                for config_info in configs:
                    try:
                        # This would call the actual calculation script
                        # For now, we'll simulate with dummy data
                        result_data = {
                            "param_id": param_id,
                            "variation": config_info['variation'],
                            "npv": 1000000 * (1 + config_info['variation']/100),  # Dummy calculation
                            "irr": 0.15 * (1 + config_info['variation']/200),     # Dummy calculation
                        }
                        
                        # Store the calculation result
                        result_path = self.manager.store_calculation_result(
                            version, param_id, compare_to_key, result_data, mode
                        )
                        
                        calculation_results.append({
                            "config": config_info,
                            "result": result_data,
                            "result_path": str(result_path)
                        })
                        
                    except Exception as e:
                        error = f"Error calculating results for {param_id} with variation {config_info['variation']}: {str(e)}"
                        self.logger.error(error)
                        results["errors"].append({"param_id": param_id, "error": error})
                
                # Generate requested plot types
                plot_paths = []
                plot_types = []
                if config.get('waterfall'): plot_types.append('waterfall')
                if config.get('bar'): plot_types.append('bar')
                if config.get('point'): plot_types.append('point')
                
                comparison_type = config.get('comparisonType', 'primary')
                
                for plot_type in plot_types:
                    try:
                        # This would call the actual plotting function
                        # For now, we'll just log the intent
                        self.logger.info(f"Would generate {plot_type} plot for {param_id} vs {compare_to_key}")
                        
                        # In a full implementation, call the actual plotting function here
                        """
                        plot_path = self.manager.generate_plot(
                            version, param_id, compare_to_key, mode, 
                            plot_type, comparison_type, result_path
                        )
                        plot_paths.append(str(plot_path))
                        """
                        
                    except Exception as e:
                        error = f"Error generating {plot_type} plot for {param_id}: {str(e)}"
                        self.logger.error(error)
                        results["errors"].append({"param_id": param_id, "error": error})
                
                # Record successful processing
                results["parameters_processed"].append({
                    "param_id": param_id,
                    "configs": len(configs),
                    "calculations": len(calculation_results),
                    "plots": len(plot_types)
                })
                
            except Exception as e:
                error = f"Unexpected error processing {param_id}: {str(e)}"
                self.logger.error(error)
                results["errors"].append({"param_id": param_id, "error": error})
        
        # Organize all sensitivity outputs
        try:
            organize_plots_result = organize_sensitivity_plots(self.original_dir)
            organize_html_result = organize_sensitivity_html(self.original_dir)
            
            results["organization"] = {
                "plots": organize_plots_result,
                "html": organize_html_result
            }
        except Exception as e:
            error = f"Error organizing sensitivity outputs: {str(e)}"
            self.logger.error(error)
            results["errors"].append({"component": "organization", "error": error})
        
        return results
    
    def run_calculation_with_sensitivity(self, version, calculation_script_path, selected_v, selected_f, 
                                        target_row, calculation_option, tolerance_lower, tolerance_upper, 
                                        increase_rate, decrease_rate, sensitivity_params):
        """
        Run a calculation that includes sensitivity analysis.
        This is meant to be called from the main Calculations.py script.
        
        Args:
            version: Version number
            calculation_script_path: Path to the calculation script
            selected_v, selected_f: V and F state dictionaries
            target_row: Target row for calculation
            calculation_option: Calculation option (e.g., 'calculateForPrice')
            tolerance_lower, tolerance_upper: Tolerance bounds
            increase_rate, decrease_rate: Adjustment rates
            sensitivity_params: Sensitivity parameters
            
        Returns:
            tuple: (success, error_message)
        """
        try:
            # First, run the baseline calculation
            self.logger.info(f"Running baseline calculation for version {version}")
            
            result = subprocess.run(
                [
                    'python',
                    calculation_script_path,
                    str(version),
                    json.dumps(selected_v),
                    json.dumps(selected_f),
                    str(target_row),
                    calculation_option,
                    str(tolerance_lower),
                    str(tolerance_upper),
                    str(increase_rate),
                    str(decrease_rate),
                    "{}"  # Empty sensitivity params for baseline
                ],
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                error_msg = f"Baseline calculation failed: {result.stderr}"
                self.logger.error(error_msg)
                return False, error_msg
            
            # If no sensitivity parameters, we're done
            if not sensitivity_params:
                return True, None
                
            # Process the sensitivity parameters
            sensitivity_result = self.process_sensitivity_request(version, sensitivity_params)
            
            # Check for errors
            if sensitivity_result["errors"]:
                error_msg = f"Sensitivity analysis completed with {len(sensitivity_result['errors'])} errors"
                self.logger.warning(error_msg)
                # We don't fail the whole operation for sensitivity errors
            
            return True, None
            
        except Exception as e:
            error_msg = f"Error running calculation with sensitivity: {str(e)}"
            self.logger.exception(error_msg)
            return False, error_msg

# Create a singleton instance
sensitivity_integration = SensitivityIntegration()
```

## 7. Update to Calculations.py Run Route

```python
# Modifications to Calculations.py run_scripts function

@app.route('/run', methods=['POST'])
def run_scripts():
    try:
        # Existing code for extracting and validating parameters...
        
        # Change to script directory for relative path operations
        os.chdir(SCRIPT_DIR)

        # Process each version
        calculation_script = CALCULATION_SCRIPTS[selected_calculation_option]
        for version in selected_versions:
            logger.info(f"Processing version {version}")
            
            # Check for version-specific optimization parameters
            version_tolerance_lower = tolerance_lower
            version_tolerance_upper = tolerance_upper
            version_increase_rate = increase_rate
            version_decrease_rate = decrease_rate
            
            # Override with version-specific parameters if provided
            if str(version) in optimization_params:
                # Existing code for handling version-specific params...
            
            # Import and use the sensitivity integration
            from sensitivity_integration import sensitivity_integration
            
            success, error = sensitivity_integration.run_calculation_with_sensitivity(
                version,
                calculation_script,
                selected_v,
                selected_f,
                target_row,
                selected_calculation_option,
                version_tolerance_lower,
                version_tolerance_upper,
                version_increase_rate,
                version_decrease_rate,
                sen_parameters
            )
            
            if not success:
                logger.error(f"Error processing version {version} with sensitivity: {error}")
                return jsonify({"error": error}), 500

        # Rest of the existing code...
    
    except Exception as e:
        # Existing error handling...
```

## 8. Enhanced Routes Blueprint

```python
# updated_sensitivity_routes.py
from flask import Blueprint, request, jsonify, send_file, Response
import logging
import os
import json
import time
from datetime import datetime
from pathlib import Path

# Import our custom modules
from sensitivity_integration import sensitivity_integration

sensitivity_routes = Blueprint('sensitivity_routes', __name__)

@sensitivity_routes.route('/sensitivity/run', methods=['POST'])
def run_sensitivity_analysis():
    """
    Standalone endpoint to run sensitivity analysis for a specific version.
    This is useful for running sensitivity analysis separately from the main calculation.
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No data provided"}), 400
            
        version = data.get('version')
        if not version:
            return jsonify({"error": "No version specified"}), 400
            
        sensitivity_params = data.get('senParameters', {})
        
        # Run the analysis
        start_time = time.time()
        results = sensitivity_integration.process_sensitivity_request(
            version, sensitivity_params
        )
        
        # Add timing information
        processing_time = time.time() - start_time
        results["processing_time"] = f"{processing_time:.2f}s"
        
        return jsonify(results)
        
    except Exception as e:
        logging.error(f"Error running sensitivity analysis: {str(e)}")
        return jsonify({"error": str(e)}), 500

@sensitivity_routes.route('/sensitivity/albums/<version>', methods=['GET'])
def get_sensitivity_albums(version):
    """
    Get all available sensitivity analysis albums for a version.
    This consolidates both plot and HTML albums in one response.
    """
    try:
        # Paths to the album directories
        base_dir = sensitivity_integration.original_dir
        results_dir = base_dir / f"Batch({version})" / f"Results({version})"
        plot_albums_dir = results_dir / "SensitivityPlots"
        html_albums_dir = results_dir / "SensitivityHTML"
        
        albums = {
            "version": version,
            "timestamp": datetime.now().isoformat(),
            "plot_albums": [],
            "html_albums": []
        }
        
        # Get plot albums
        if os.path.exists(plot_albums_dir):
            for album_name in os.listdir(plot_albums_dir):
                album_dir = plot_albums_dir / album_name
                if os.path.isdir(album_dir):
                    # Look for metadata file
                    metadata_file = album_dir / "metadata.json"
                    if os.path.exists(metadata_file):
                        with open(metadata_file, 'r') as f:
                            metadata = json.load(f)
                    else:
                        # Create basic metadata if file doesn't exist
                        metadata = {
                            "display_name": album_name.replace("_", " "),
                            "files": [f for f in os.listdir(album_dir) if f.lower().endswith('.png')]
                        }
                    
                    # Add album information
                    albums["plot_albums"].append({
                        "name": album_name,
                        "path": str(album_dir.relative_to(base_dir)),
                        "metadata": metadata,
                        "file_count": len(metadata.get("files", []))
                    })
        
        # Get HTML albums
        if os.path.exists(html_albums_dir):
            for album_name in os.listdir(html_albums_dir):
                album_dir = html_albums_dir / album_name
                if os.path.isdir(album_dir):
                    # Look for metadata file
                    metadata_file = album_dir / "metadata.json"
                    if os.path.exists(metadata_file):
                        with open(metadata_file, 'r') as f:
                            metadata = json.load(f)
                    else:
                        # Create basic metadata if file doesn't exist
                        metadata = {
                            "display_name": album_name.replace("_", " "),
                            "files": [f for f in os.listdir(album_dir) if f.lower().endswith('.html')]
                        }
                    
                    # Add album information
                    albums["html_albums"].append({
                        "name": album_name,
                        "path": str(album_dir.relative_to(base_dir)),
                        "metadata": metadata,
                        "file_count": len(metadata.get("files", []))
                    })
        
        return jsonify(albums)
        
    except Exception as e:
        logging.error(f"Error retrieving sensitivity albums: {str(e)}")
        return jsonify({"error": str(e)}), 500

@sensitivity_routes.route('/sensitivity/plots/<version>/<album_name>', methods=['GET'])
def get_sensitivity_plots(version, album_name):
    """
    Get all plots in a specific sensitivity album.
    """
    try:
        base_dir = sensitivity_integration.original_dir
        album_dir = base_dir / f"Batch({version})" / f"Results({version})" / "SensitivityPlots" / album_name
        
        if not os.path.exists(album_dir):
            return jsonify({"error": f"Album {album_name} not found"}), 404
        
        # Get metadata
        metadata_file = album_dir / "metadata.json"
        if os.path.exists(metadata_file):
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
        else:
            metadata = {
                "display_name": album_name.replace("_", " ")
            }
        
        # Get plots
        plots = []
        for file_name in os.listdir(album_dir):
            if file_name.lower().endswith('.png'):
                file_path = album_dir / file_name
                
                # Extract parameter info if possible
                param_match = None
                if "_vs_" in file_name:
                    parts = file_name.split("_vs_")
                    if len(parts) == 2:
                        param_id = parts[0]
                        remaining = parts[1].split("_")
                        if len(remaining) >= 1:
                            compare_to = remaining[0].split(".")[0]  # Remove extension
                            param_match = {
                                "param_id": param_id,
                                "compare_to": compare_to
                            }
                
                # Add plot information
                plots.append({
                    "name": file_name,
                    "path": str(file_path.relative_to(base_dir)),
                    "url": f"/images/Original/{file_path.relative_to(base_dir)}",
                    "size": os.path.getsize(file_path),
                    "param_info": param_match
                })
        
        response = {
            "version": version,
            "album": album_name,
            "metadata": metadata,
            "plots": plots
        }
        
        return jsonify(response)
        
    except Exception as e:
        logging.error(f"Error retrieving sensitivity plots: {str(e)}")
        return jsonify({"error": str(e)}), 500

@sensitivity_routes.route('/sensitivity/html/<version>/<album_name>', methods=['GET'])
def get_sensitivity_html(version, album_name):
    """
    Get all HTML files in a specific sensitivity album.
    """
    try:
        base_dir = sensitivity_integration.original_dir
        album_dir = base_dir / f"Batch({version})" / f"Results({version})" / "SensitivityHTML" / album_name
        
        if not os.path.exists(album_dir):
            return jsonify({"error": f"Album {album_name} not found"}), 404
        
        # Get metadata
        metadata_file = album_dir / "metadata.json"
        if os.path.exists(metadata_file):
            with open(metadata_file, 'r') as f:
                metadata = json.load(f)
        else:
            metadata = {
                "display_name": album_name.replace("_", " ")
            }
        
        # Get HTML files
        html_files = []
        for file_name in os.listdir(album_dir):
            if file_name.lower().endswith('.html'):
                file_path = album_dir / file_name
                
                try:
                    # Read the content
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # Extract parameter info if possible
                    param_match = None
                    if "_vs_" in file_name:
                        parts = file_name.split("_vs_")
                        if len(parts) == 2:
                            param_id = parts[0]
                            remaining = parts[1].split("_")
                            if len(remaining) >= 1:
                                compare_to = remaining[0].split(".")[0]  # Remove extension
                                param_match = {
                                    "param_id": param_id,
                                    "compare_to": compare_to
                                }
                    
                    # Add file information
                    html_files.append({
                        "name": file_name,
                        "path": str(file_path.relative_to(base_dir)),
                        "url": f"/Original/{file_path.relative_to(base_dir)}",
                        "content": content,  # Include the content directly
                        "size": os.path.getsize(file_path),
                        "param_info": param_match
                    })
                except Exception as e:
                    logging.error(f"Error reading HTML file {file_path}: {str(e)}")
        
        response = {
            "version": version,
            "album": album_name,
            "metadata": metadata,
            "html_files": html_files
        }
        
        return jsonify(response)
        
    except Exception as e:
        logging.error(f"Error retrieving sensitivity HTML: {str(e)}")
        return jsonify({"error": str(e)}), 500

@sensitivity_routes.route('/sensitivity/results/<version>', methods=['GET'])
def get_sensitivity_results(version):
    """
    Get consolidated results of all sensitivity analyses for a version.
    """
    try:
        # Paths to search for result files
        base_dir = sensitivity_integration.original_dir
        results_dir = base_dir / f"Batch({version})" / f"Results({version})" / "Sensitivity"
        
        if not os.path.exists(results_dir):
            return jsonify({"error": f"No sensitivity results found for version {version}"}), 404
        
        # Consolidated results structure
        consolidated = {
            "version": version,
            "timestamp": datetime.now().isoformat(),
            "parameters": {},
            "comparisons": []
        }
        
        # Search for result files in all subdirectories
        for mode in ["Symmetrical", "Multipoint"]:
            mode_dir = results_dir / mode
            if not os.path.exists(mode_dir):
                continue
                
            # Find all result JSON files
            for root, _, files in os.walk(mode_dir):
                for file_name in files:
                    if file_name.endswith("_results.json"):
                        try:
                            file_path = Path(root) / file_name
                            with open(file_path, 'r') as f:
                                result_data = json.load(f)
                            
                            # Extract information
                            metadata = result_data.get('metadata', {})
                            param_id = metadata.get('param_id')
                            compare_to_key = metadata.get('compare_to_key')
                            
                            if param_id and compare_to_key:
                                # Add parameter info if not already present
                                if param_id not in consolidated["parameters"]:
                                    consolidated["parameters"][param_id] = metadata.get('property_info', {
                                        "id": param_id,
                                        "display_name": param_id
                                    })
                                
                                # Add comparison info
                                comparison_key = f"{param_id}_vs_{compare_to_key}"
                                consolidated["comparisons"].append({
                                    "param_id": param_id,
                                    "compare_to": compare_to_key,
                                    "mode": mode,
                                    "key": comparison_key,
                                    "results": result_data.get('results', {}),
                                    "result_file": str(file_path.relative_to(base_dir))
                                })
                        except Exception as e:
                            logging.error(f"Error processing result file {file_name}: {str(e)}")
        
        return jsonify(consolidated)
        
    except Exception as e:
        logging.error(f"Error retrieving sensitivity results: {str(e)}")
        return jsonify({"error": str(e