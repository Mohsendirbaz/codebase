@sensitivity_routes.route('/sensitivity/results/<version>', methods=['GET'])
def get_sensitivity_results(version):
    """
    Get consolidated results of all sensitivity analyses for a version.
    """
    try:
        # Paths to search for result files
        base_dir = sensitivity_integration.original_dir
        results_dir = base_dir / f"Batch({version})" / f"Results({version})" / "Sensitivity"
        
        if not os.path.exists(results_dir):
            return jsonify({"error": f"No sensitivity results found for version {version}"}), 404
        
        # Consolidated results structure
        consolidated = {
            "version": version,
            "timestamp": datetime.now().isoformat(),
            "parameters": {},
            "comparisons": []
        }
        
        # Search for result files in all subdirectories
        for mode in ["Symmetrical", "Multipoint"]:
            mode_dir = results_dir / mode
            if not os.path.exists(mode_dir):
                continue
                
            # Find all result JSON files
            for root, _, files in os.walk(mode_dir):
                for file_name in files:
                    if file_name.endswith("_results.json"):
                        try:
                            file_path = Path(root) / file_name
                            with open(file_path, 'r') as f:
                                result_data = json.load(f)
                            
                            # Extract information
                            metadata = result_data.get('metadata', {})
                            param_id = metadata.get('param_id')
                            compare_to_key = metadata.get('compare_to_key')
                            
                            if param_id and compare_to_key:
                                # Add parameter info if not already present
                                if param_id not in consolidated["parameters"]:
                                    consolidated["parameters"][param_id] = metadata.get('property_info', {
                                        "id": param_id,
                                        "display_name": param_id
                                    })
                                
                                # Add comparison info
                                comparison_key = f"{param_id}_vs_{compare_to_key}"
                                consolidated["comparisons"].append({
                                    "param_id": param_id,
                                    "compare_to": compare_to_key,
                                    "mode": mode,
                                    "key": comparison_key,
                                    "results": result_data.get('results', {}),
                                    "result_file": str(file_path.relative_to(base_dir))
                                })
                        except Exception as e:
                            logging.error(f"Error processing result file {file_name}: {str(e)}")
        
        return jsonify(consolidated)
        
    except Exception as e:
        logging.error(f"Error retrieving sensitivity results: {str(e)}")
        return jsonify({"error": str(e)}), 500

@sensitivity_routes.route('/sensitivity/serve-file/<version>/<path:file_path>', methods=['GET'])
def serve_sensitivity_file(version, file_path):
    """
    Generic endpoint to serve any file from the sensitivity analysis directories.
    This provides a unified way to access plots, HTML files, and results.
    """
    try:
        base_dir = sensitivity_integration.original_dir
        batch_dir = base_dir / f"Batch({version})"
        
        # Normalize the file path
        if file_path.startswith('/'):
            file_path = file_path[1:]
        
        # Construct the full path
        full_path = batch_dir / file_path
        
        if not os.path.exists(full_path):
            return jsonify({"error": f"File not found: {file_path}"}), 404
        
        # Determine content type based on file extension
        content_type = 'application/octet-stream'  # Default
        
        if file_path.lower().endswith('.png'):
            content_type = 'image/png'
        elif file_path.lower().endswith('.jpg') or file_path.lower().endswith('.jpeg'):
            content_type = 'image/jpeg'
        elif file_path.lower().endswith('.html'):
            content_type = 'text/html'
        elif file_path.lower().endswith('.json'):
            content_type = 'application/json'
        elif file_path.lower().endswith('.csv'):
            content_type = 'text/csv'
        
        return send_file(full_path, mimetype=content_type)
        
    except Exception as e:
        logging.error(f"Error serving file {file_path}: {str(e)}")
        return jsonify({"error": str(e)}), 500

@sensitivity_routes.route('/sensitivity/stream-status/<version>/<param_id>', methods=['GET'])
def stream_sensitivity_status(version, param_id):
    """
    Stream real-time status updates for a sensitivity analysis using SSE.
    """
    def generate():
        """Generator function for SSE stream."""
        try:
            # Initial connection message
            yield f"data: {json.dumps({'status': 'connected', 'version': version, 'param_id': param_id})}\n\n"
            
            # Path to the status file
            status_file = (sensitivity_integration.original_dir / 
                          f"Batch({version})" / f"Results({version})" / 
                          "Sensitivity" / f"{param_id}_status.json")
            
            last_modified = 0
            consecutive_errors = 0
            max_errors = 20
            
            while consecutive_errors < max_errors:
                try:
                    # Check if status file exists
                    if os.path.exists(status_file):
                        current_modified = os.path.getmtime(status_file)
                        
                        # If file has been modified
                        if current_modified > last_modified:
                            last_modified = current_modified
                            
                            # Read and parse the file
                            with open(status_file, 'r') as f:
                                status_data = json.load(f)
                            
                            # Send the data
                            yield f"data: {json.dumps(status_data)}\n\n"
                            
                            # If analysis is complete, end the stream
                            if status_data.get('complete', False):
                                yield f"data: {json.dumps({'status': 'completed', 'message': 'Analysis complete'})}\n\n"
                                break
                            
                            consecutive_errors = 0
                        else:
                            # Send heartbeat every 5 seconds if file exists but hasn't changed
                            yield f"data: {json.dumps({'heartbeat': True})}\n\n"
                    else:
                        consecutive_errors += 1
                        if consecutive_errors % 5 == 0:
                            logging.warning(f"Status file not found for {param_id}, consecutive errors: {consecutive_errors}")
                except Exception as e:
                    consecutive_errors += 1
                    logging.error(f"Error in status stream: {str(e)}")
                
                # Sleep before next check
                time.sleep(1)
            
            if consecutive_errors >= max_errors:
                yield f"data: {json.dumps({'error': 'Too many consecutive errors', 'complete': True})}\n\n"
                
        except GeneratorExit:
            # Client disconnected
            logging.info(f"Client disconnected from status stream for {param_id}")
        except Exception as e:
            logging.error(f"Error in status stream generator: {str(e)}")
            yield f"data: {json.dumps({'error': str(e), 'complete': True})}\n\n"
    
    return Response(generate(), mimetype='text/event-stream')

## 9. Application Configuration Integration

```python
# app.py (Main application entry point)
from flask import Flask
from flask_cors import CORS
import logging
import os
from datetime import datetime

# Import Blueprints
from sensitivity_routes import sensitivity_routes

def create_app():
    """Create and configure the Flask application."""
    app = Flask(__name__)
    CORS(app)
    
    # Configure logging
    log_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Logs")
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, f"sensitivity_api_{datetime.now().strftime('%Y%m%d')}.log")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file),
            logging.StreamHandler()
        ]
    )
    
    # Register blueprints
    app.register_blueprint(sensitivity_routes, url_prefix='/api')
    
    @app.route('/health')
    def health_check():
        """Health check endpoint."""
        return {"status": "healthy", "timestamp": datetime.now().isoformat()}
    
    return app

# Run the application
if __name__ == '__main__':
    app = create_app()
    app.run(host='0.0.0.0', port=5010, debug=True)
```

## 10. Installation and Setup Script

```python
# setup_sensitivity.py
import os
import sys
import logging
import shutil
from pathlib import Path
import subprocess

def setup_sensitivity_analysis():
    """
    Set up the sensitivity analysis infrastructure.
    
    This script:
    1. Creates required directories
    2. Copies necessary scripts to the correct locations
    3. Initializes required files
    """
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    logger = logging.getLogger("setup")
    
    # Determine base directory
    base_dir = Path(os.path.dirname(os.path.abspath(__file__)))
    
    try:
        # Create Logs directory
        logs_dir = base_dir / "Logs"
        os.makedirs(logs_dir, exist_ok=True)
        logger.info(f"Created Logs directory at {logs_dir}")
        
        # Create directories for each batch
        original_dir = base_dir.parent / "public" / "Original"
        if not os.path.exists(original_dir):
            logger.warning(f"Original directory not found at {original_dir}")
            create = input("Create public/Original directory structure? (y/n): ")
            if create.lower() == 'y':
                os.makedirs(original_dir, exist_ok=True)
                logger.info(f"Created Original directory at {original_dir}")
            else:
                logger.info("Skipping Original directory creation")
        
        # Create sensitivity directories for existing batches
        if os.path.exists(original_dir):
            batch_dirs = [d for d in os.listdir(original_dir) if d.startswith("Batch(") and d.endswith(")")]
            
            for batch_dir in batch_dirs:
                # Extract version number
                version = batch_dir.split("(")[1].split(")")[0]
                
                # Create sensitivity directories
                results_dir = original_dir / batch_dir / f"Results({version})"
                sensitivity_dir = results_dir / "Sensitivity"
                sensitivity_plots_dir = results_dir / "SensitivityPlots"
                sensitivity_html_dir = results_dir / "SensitivityHTML"
                
                for directory in [sensitivity_dir, sensitivity_plots_dir, sensitivity_html_dir]:
                    os.makedirs(directory, exist_ok=True)
                    logger.info(f"Created directory: {directory}")
                
                # Create subdirectories for different analysis types
                for mode in ["Symmetrical", "Multipoint"]:
                    mode_dir = sensitivity_dir / mode
                    os.makedirs(mode_dir, exist_ok=True)
                    logger.info(f"Created mode directory: {mode_dir}")
                    
                    # Create plot type directories
                    for plot_type in ["waterfall", "bar", "point"]:
                        plot_dir = mode_dir / plot_type
                        os.makedirs(plot_dir, exist_ok=True)
                        logger.info(f"Created plot type directory: {plot_dir}")
        
        # Install required packages
        logger.info("Installing required packages...")
        subprocess.run([sys.executable, "-m", "pip", "install", "pandas", "numpy", "flask", "flask-cors", "matplotlib", "plotly"], 
                      check=True)
        
        logger.info("Setup completed successfully!")
        
    except Exception as e:
        logger.error(f"Error during setup: {str(e)}")
        return False
    
    return True

if __name__ == "__main__":
    setup_sensitivity_analysis()
```

## Implementation Plan

1. **Create Core Directory Structure**:
   - Set up the main directory structure with the `setup_sensitivity.py` script
   - Ensure all required directories are in place for each version

2. **Deploy Core Manager and Organizers**:
   - Deploy `sensitivity_analysis_manager.py`, `sensitivity_plot_organizer.py`, and `sensitivity_html_organizer.py`
   - Ensure they have the correct permissions and dependencies

3. **Integrate with Calculations Module**:
   - Add the `sensitivity_integration.py` to link with existing calculation functionality
   - Modify the run script in `Calculations.py` to use the integration

4. **Set Up API Routes**:
   - Deploy the enhanced `sensitivity_routes.py` blueprint
   - Register with the main Flask application

5. **Testing Phase**:
   - Test individual components separately
   - Perform end-to-end testing with sample data
   - Validate file organization and access

This comprehensive solution provides a robust framework for organizing and serving sensitivity analysis results. It maintains compatibility with the existing calculation and visualization systems while adding a structured approach to file management and retrieval.